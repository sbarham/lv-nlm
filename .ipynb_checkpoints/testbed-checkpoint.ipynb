{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Args: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from multiprocessing import cpu_count\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# torch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ours\n",
    "from corpus.ptb import PTB\n",
    "import util\n",
    "from util.utils import to_var, expierment_name\n",
    "from models.bowman import SentenceVAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_datasets(args):\n",
    "    splits = [util.TRAIN, util.VAL] + ([util.TEST] if args.test else [])\n",
    "    datasets = OrderedDict()\n",
    "    datasets.splits = splits\n",
    "    \n",
    "    # create train, validation, and possibly test split\n",
    "    for split in datasets.splits:\n",
    "        datasets[split] = PTB(\n",
    "            data_dir=args.data_dir,\n",
    "            split=split,\n",
    "            create_data=args.create_data,\n",
    "            max_sequence_length=args.max_sequence_length,\n",
    "            min_occ=args.min_occ,\n",
    "            embeddings=args.embeddings\n",
    "        )\n",
    "    \n",
    "    # return the splits\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(args, datasets):\n",
    "    model = SentenceVAE(\n",
    "            vocab_size=datasets[util.TRAIN].vocab_size,\n",
    "            sos_idx=datasets[util.TRAIN].sos_idx,\n",
    "            eos_idx=datasets[util.TRAIN].eos_idx,\n",
    "            pad_idx=datasets[util.TRAIN].pad_idx,\n",
    "            unk_idx=datasets[util.TRAIN].unk_idx,\n",
    "            max_sequence_length=args.max_sequence_length,\n",
    "            embedding_size=args.embedding_size,\n",
    "            rnn_type=args.rnn_type,\n",
    "            hidden_size=args.hidden_size,\n",
    "            word_dropout=args.word_dropout,\n",
    "            embedding_dropout=args.embedding_dropout,\n",
    "            latent_size=args.latent_size,\n",
    "            num_layers=args.num_layers,\n",
    "            bidirectional=args.bidirectional\n",
    "        )\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kl_anneal_function(anneal_function, step, k, x0):\n",
    "    if anneal_function == 'logistic':\n",
    "        return float(1.0 / (1.0 + np.exp(-k * (step - x0))))\n",
    "    elif anneal_function == 'linear':\n",
    "        return min(1.0, step / x0)\n",
    "    elif anneal_function == 'const':\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_fn(logp, target, length, mean, logv, anneal_function, step, k, x0, pad_idx):\n",
    "    NLL = torch.nn.NLLLoss(reduction='sum', ignore_index=pad_idx)\n",
    "    \n",
    "    # cut-off unnecessary padding from target, and flatten\n",
    "    target = target[:, :torch.max(length).item()].contiguous().view(-1)\n",
    "    logp = logp.view(-1, logp.size(2))\n",
    "        \n",
    "    # Negative Log Likelihood\n",
    "    NLL_loss = NLL(logp, target)\n",
    "\n",
    "    # KL Divergence\n",
    "    KL_loss = -0.5 * torch.sum(1 + logv - mean.pow(2) - logv.exp())\n",
    "    KL_weight = kl_anneal_function(anneal_function, step, k, x0)\n",
    "\n",
    "    return NLL_loss, KL_loss, KL_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def idx2word(sents, i2w, pad_idx):\n",
    "    sent_str = [str()] * len(sents)\n",
    "\n",
    "    for sent_idx, sent in enumerate(sents):\n",
    "        for word_id in sent:\n",
    "            try:\n",
    "                word_id = word_id.item()\n",
    "            except: pass\n",
    "            \n",
    "            if word_id == pad_idx:\n",
    "                break\n",
    "            \n",
    "            sent_str[sent_idx] += (i2w[word_id] + \" \")\n",
    "\n",
    "        sent_str[sent_idx] = sent_str[sent_idx].strip()\n",
    "\n",
    "\n",
    "    return sent_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model/Runtime Arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep Dataset/Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, datasets, args):\n",
    "    print(model)\n",
    "    \n",
    "    timestamp = time.strftime('%Y-%b-%d-%H:%M:%S', time.gmtime())\n",
    "\n",
    "    # create the directory for saving this model\n",
    "    args.save_model_path = os.path.join(util.MODEL_DIR, timestamp)\n",
    "    os.makedirs(args.save_model_path)\n",
    "    \n",
    "    # create the optimizer, the tracker, and initialize the step to 0\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "    trackers = {split: defaultdict(list) for split in datasets.splits}\n",
    "    step = 0\n",
    "    best = float('inf')\n",
    "    \n",
    "    # get the pad index, for convenience\n",
    "    pad_idx = datasets['train'].get_w2i()['<pad>']\n",
    "    \n",
    "    # go!\n",
    "    for epoch in range(args.epochs):\n",
    "        for split in datasets.splits:\n",
    "            print(\"SPLIT = {}\".format(split))\n",
    "            \n",
    "            data_loader = DataLoader(\n",
    "                dataset=datasets[split],\n",
    "                batch_size=args.batch_size,\n",
    "                shuffle=split=='train',\n",
    "                num_workers=cpu_count(),\n",
    "                pin_memory=torch.cuda.is_available()\n",
    "            )\n",
    "\n",
    "            # Enable/Disable Dropout\n",
    "            if split == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            for iteration, batch in enumerate(data_loader):\n",
    "                batch_size = batch['input'].size(0)\n",
    "\n",
    "                for k, v in batch.items():\n",
    "                    if torch.is_tensor(v):\n",
    "                        batch[k] = to_var(v)\n",
    "\n",
    "                # Forward pass\n",
    "                logp, mean, logv, z = model(batch['input'], batch['length'])\n",
    "\n",
    "                # loss calculation\n",
    "                NLL_loss, KL_loss, KL_weight = loss_fn(logp, batch['target'],\n",
    "                    batch['length'], mean, logv, args.anneal_function, step, args.k, args.x0, pad_idx)\n",
    "\n",
    "                loss = (NLL_loss + KL_weight * KL_loss) / batch_size\n",
    "\n",
    "                # backward + optimization\n",
    "                if split == 'train':\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    step += 1\n",
    "\n",
    "                if iteration % args.print_every == 0 or iteration+1 == len(data_loader):\n",
    "                    print(\"%s Batch %04d/%i, Loss %9.4f, NLL-Loss %9.4f, KL-Loss %9.4f, KL-Weight %6.3f\"\n",
    "                        % (split.upper(),\n",
    "                           iteration,\n",
    "                           len(data_loader) - 1,\n",
    "                           loss.item(),\n",
    "                           NLL_loss.item() / batch_size,\n",
    "                           KL_loss.item() / batch_size,\n",
    "                           KL_weight))\n",
    "\n",
    "                trackers[split]['ELBO'].append(loss.item())\n",
    "                trackers[split]['NLL'].append(NLL_loss.item() / batch_size)\n",
    "                trackers[split]['KLL'].append(KL_loss.item() / batch_size)\n",
    "                trackers[split]['KL_weight'].append(KL_weight)\n",
    "                \n",
    "#                 if split == 'valid':\n",
    "#                     i2w = datasets['train'].get_i2w()\n",
    "#                     trackers[split]['target_sents'] += idx2word(batch['target'].data, i2w=i2w, pad_idx=pad_idx)\n",
    "#                     trackers[split]['z'].append(z.tolist())\n",
    "\n",
    "            \n",
    "            \"\"\"\n",
    "            END OF BATCH\n",
    "            \"\"\"\n",
    "            print(\"%s Epoch %02d/%i, Mean ELBO %9.4f\" % (split.upper(), epoch, args.epochs, np.mean(trackers[split]['ELBO'])))\n",
    "\n",
    "            # save a dump of all sentences and the encoded latent space\n",
    "#             if split == 'valid':\n",
    "#                 dump = {'target_sents':trackers[split]['target_sents'], 'z':trackers[split]['z']}\n",
    "#                 if not os.path.exists(os.path.join('dumps', ts)):\n",
    "#                     os.makedirs('dumps/' + ts)\n",
    "#                 with open(os.path.join('dumps/'+ts+'/valid_E%i.pickle' % epoch), 'wb') as dump_file:\n",
    "#                     pickle.dump(dump, dump_file)\n",
    "\n",
    "            # save checkpoint\n",
    "            if split == 'train':                \n",
    "                # save checkpoint\n",
    "                checkpoint_path = os.path.join(args.save_model_path, \"E%i.pytorch\" % (epoch))\n",
    "                torch.save(model.state_dict(), checkpoint_path)\n",
    "                print(\"Model saved at %s\" % checkpoint_path)\n",
    "                \n",
    "                # check if best checkpoint so far\n",
    "                if np.mean(trackers[split]['ELBO']) < best:\n",
    "                    best = np.mean(trackers[split]['ELBO'])\n",
    "                    args.load_checkpoint = 'E{}.pytorch'.format(epoch)\n",
    "                \n",
    "    return trackers, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exponential_smoothing(ys, beta=0.8, ub=math.inf, lb=-math.inf):\n",
    "    \"\"\"\n",
    "    This is ugly, and I should have used a comprehension, but\n",
    "    it'll get the job done. I made it a function because I suspect\n",
    "    I may need it later.\n",
    "    \"\"\"\n",
    "    smooth_ys = [ys[0]]\n",
    "    for y in ys:\n",
    "        if y > ub or y < lb:\n",
    "            smooth_ys.append(smooth_ys[-1])\n",
    "        else:\n",
    "            smooth_ys.append(beta * smooth_ys[-1] + (1 - beta) * y)\n",
    "    return smooth_ys[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(ELBO, NLL, KL, title, fname=None, xlabel=\"Epochs\", ylabel=\"Measurements\", hline=None, epochs=None):\n",
    "    \"\"\"\n",
    "    Just a *slight* abstraction over pyplot to ease development a bit.\n",
    "    \"\"\"\n",
    "    xs = list(range(len(ELBO)))\n",
    "    if epochs is not None:\n",
    "        xs = [x / len(xs) * epochs for x in xs]\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    if hline:\n",
    "        plt.axhline(y=hline, color='r', linestyle='-')\n",
    "    \n",
    "    plt.plot(xs, ELBO, label=\"ELBO\")\n",
    "    plt.plot(xs, NLL, label=\"NLL Loss\", c='blue')\n",
    "    plt.plot(xs, KL, label=\"KL Loss\", c='red')\n",
    "    plt.legend()\n",
    "    \n",
    "    if fname:\n",
    "        plt.savefig(fname)\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_elbo(ELBO, fname=None, title='ELBO', xlabel=\"Epochs\", ylabel=\"ELBO\", hline=None, epochs=None):\n",
    "    \"\"\"\n",
    "    Just a *slight* abstraction over pyplot to ease development a bit.\n",
    "    \"\"\"\n",
    "    xs = list(range(len(ELBO)))\n",
    "    if epochs is not None:\n",
    "        xs = [x / len(xs) * epochs for x in xs]\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    \n",
    "    plt.plot(xs, ELBO, label=\"ELBO\")\n",
    "    plt.legend()\n",
    "        \n",
    "    if fname:\n",
    "        plt.savefig(fname)\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def graph(trackers, datasets, args):\n",
    "    for split in datasets.splits:\n",
    "        fname = '{}_perf:emb{}-z{}-lstm{}-maxlen{}'.format(\n",
    "            split,\n",
    "            args.embedding_size,\n",
    "            args.latent_size,\n",
    "            args.hidden_size,\n",
    "            args.max_sequence_length\n",
    "        )\n",
    "        \n",
    "        fname = os.path.join(args.save_model_path, fname)\n",
    "        \n",
    "        plot(\n",
    "            fname=fname,\n",
    "            ELBO=exponential_smoothing(trackers[split]['ELBO']),\n",
    "            KL=exponential_smoothing(trackers[split]['KLL']),\n",
    "            NLL=exponential_smoothing(trackers[split]['NLL']),\n",
    "            title='S-VAE *{}* Performance\\n(Mikolov\\'s Simplified PTB, max length={})'.format(\n",
    "                split,\n",
    "                args.max_sequence_length\n",
    "            ),\n",
    "            epochs=args.epochs\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolate(start, end, steps):\n",
    "    steps = steps + 2\n",
    "    \n",
    "    interpolation = np.zeros((start.shape[0], steps))\n",
    "\n",
    "    for dim, (s, e) in enumerate(zip(start, end)):\n",
    "        interpolation[dim] = np.linspace(s, e, steps)\n",
    "\n",
    "    return interpolation.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_args(args):\n",
    "    fname = os.path.join(args.save_model_path, 'args')\n",
    "    with open(fname, 'w+') as file:\n",
    "        lines = ['{}: {}\\n'.format(key, val) for key, val in vars(args).items()]\n",
    "        file.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_trackers(trackers, args):\n",
    "    fname = os.path.join(args.save_model_path, 'trackers.pickle')\n",
    "    with open(fname, 'wb') as file:\n",
    "        pickle.dump(trackers, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(args):\n",
    "    with open(args.data_dir + '/ptb.vocab.pickle', 'rb') as file:\n",
    "        vocab = pickle.load(file)\n",
    "\n",
    "    w2i, i2w = vocab['w2i'], vocab['i2w']\n",
    "\n",
    "    model = SentenceVAE(\n",
    "        vocab_size=len(w2i),\n",
    "        sos_idx=w2i['<sos>'],\n",
    "        eos_idx=w2i['<eos>'],\n",
    "        pad_idx=w2i['<pad>'],\n",
    "        unk_idx=w2i['<unk>'],\n",
    "        max_sequence_length=args.max_sequence_length,\n",
    "        embedding_size=args.embedding_size,\n",
    "        rnn_type=args.rnn_type,\n",
    "        hidden_size=args.hidden_size,\n",
    "        word_dropout=args.word_dropout,\n",
    "        embedding_dropout=args.embedding_dropout,\n",
    "        latent_size=args.latent_size,\n",
    "        num_layers=args.num_layers,\n",
    "        bidirectional=args.bidirectional\n",
    "        )\n",
    "\n",
    "    checkpoint_path = os.path.join(args.save_model_path, args.load_checkpoint)\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        raise FileNotFoundError(checkpoint_path)\n",
    "\n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "    print(\"Model loaded from %s\" % (checkpoint_path))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    fname = os.path.join(args.save_model_path, 'samples')\n",
    "    lines = []\n",
    "    with open(fname, 'w+') as file:\n",
    "        samples, z = model.inference(n=args.num_samples)\n",
    "        lines += ['----------SAMPLES----------']\n",
    "        lines += [line + '\\n' for line in idx2word(samples, i2w=i2w, pad_idx=w2i['<pad>'])]\n",
    "        lines += ['\\n']\n",
    "\n",
    "        z1 = torch.randn([args.latent_size]).numpy()\n",
    "        z2 = torch.randn([args.latent_size]).numpy()\n",
    "        z = to_var(torch.from_numpy(interpolate(start=z1, end=z2, steps=8)).float())\n",
    "        samples, _ = model.inference(z=z)\n",
    "        lines += ['-------SELF-GENERATED INTERPOLATION-------']\n",
    "        lines += [line + '\\n' for line in idx2word(samples, i2w=i2w, pad_idx=w2i['<pad>'])]\n",
    "        lines += ['\\n']\n",
    "\n",
    "        # pick two random sentences\n",
    "        i = random.randint(0, len(datasets['train']))\n",
    "        j = random.randint(0, len(datasets['train']))\n",
    "\n",
    "        s_i = torch.tensor([datasets['train'][i]['input']])\n",
    "        s_j = torch.tensor([datasets['train'][j]['input']])\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, _, _, z_i = model(s_i, torch.tensor([1]))\n",
    "            _, _, _, z_j = model(s_j, torch.tensor([1]))\n",
    "            \n",
    "        z1, z2 = z_i.squeeze().numpy(), z_j.squeeze().numpy()\n",
    "        z = to_var(torch.from_numpy(interpolate(start=z1, end=z2, steps=8)).float())\n",
    "        samples, _ = model.inference(z=z)\n",
    "        lines += ['-------DATA-DRIVEN INTERPOLATION----------']\n",
    "        lines += [line + '\\n'  for line in idx2word(samples, i2w=i2w, pad_idx=w2i['<pad>'])]\n",
    "        lines += ['\\n']\n",
    "        \n",
    "        print(\"wrote samples to '{}'\".format(fname))\n",
    "        file.writelines(lines)\n",
    "        \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_sentences(datasets):\n",
    "    data = datasets['train'] + datasets['valid'] + datasets['test']\n",
    "    \n",
    "    return len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_words(datasets):\n",
    "    data = datasets['train'] + datasets['valid'] + datasets['test']\n",
    "    total = 0\n",
    "    for sent in data:\n",
    "        total = total + sent['length']\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set all model/runtime arguments\n",
    "\n",
    "args = Args()\n",
    "\n",
    "args.data_dir = 'data'\n",
    "args.create_data = True\n",
    "args.max_sequence_length = 20\n",
    "args.min_occ = 1\n",
    "args.test = True\n",
    "args.epochs = 10\n",
    "args.batch_size = 64\n",
    "args.learning_rate = 0.001\n",
    "\n",
    "args.num_samples = 10\n",
    "\n",
    "args.embeddings = True\n",
    "args.embedding_size = 300\n",
    "args.rnn_type = 'gru'\n",
    "args.hidden_size = 256\n",
    "args.num_layers = 1\n",
    "args.bidirectional = False\n",
    "args.latent_size = 16\n",
    "args.word_dropout = 0.0\n",
    "args.embedding_dropout = 0.5\n",
    "\n",
    "args.anneal_function = 'logistic'\n",
    "args.k = 0.0025\n",
    "args.x0 = 2500\n",
    "\n",
    "args.print_every = 50\n",
    "args.tensorboard_logging = False\n",
    "args.logdir = 'logs'\n",
    "args.save_model_path = 'bin/good25'\n",
    "args.load_checkpoint = 'E9.pytorch'\n",
    "\n",
    "args.rnn_type = args.rnn_type.lower()\n",
    "args.anneal_function = args.anneal_function.lower()\n",
    "\n",
    "assert args.rnn_type in ['rnn', 'lstm', 'gru']\n",
    "assert args.anneal_function in ['logistic', 'linear', 'const']\n",
    "assert 0 <= args.word_dropout <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_experiment(args):\n",
    "    # create the datasets and model\n",
    "    datasets = create_datasets(args)\n",
    "\n",
    "    # create a new model\n",
    "    model = create_model(args, datasets)\n",
    "    \n",
    "    # train the model and record its performance\n",
    "    trackers, model = train(model, datasets, args)\n",
    "    \n",
    "    # write args to file\n",
    "    save_args(args)\n",
    "    \n",
    "    # save the trackers\n",
    "    save_trackers(trackers, args)\n",
    "    \n",
    "    # graph the results and save\n",
    "    graph(trackers, datasets, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Penn Treebank *train* data:\n",
      "------------------------------------------\n",
      "Creating vocab file ...\n",
      "\t[Getting word counts]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e507e3adff74628a8919af2dc9d6daf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Creating dictionaries]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffc8adecad94fed8276f20e35a01877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t[Loading pretrained GLOVE embeddings -- this may take a while the first time]\n",
      "Loaded 400000 words\n",
      "\t[Mapping vocab to GLOVE embeddings]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d25faf8e6f9a4a30ba683b6b38c12a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary created (10009 word types)!\n",
      "Creating dataset ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1ac2efbeef44208a078c5d033637be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created, with:\n",
      "\t17144 sentences\n",
      "\t236015 word tokens\n",
      "\t13.76662389174055 avg. sentence length\n",
      "\n",
      "\n",
      "Preprocessing Penn Treebank *val* data:\n",
      "------------------------------------------\n",
      "Loading vocab file ...\n",
      "Creating dataset ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b641a7042d54ea1942ab2fb653e21ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created, with:\n",
      "\t1410 sentences\n",
      "\t19458 word tokens\n",
      "\t13.8 avg. sentence length\n",
      "\n",
      "\n",
      "Preprocessing Penn Treebank *test* data:\n",
      "------------------------------------------\n",
      "Loading vocab file ...\n",
      "Creating dataset ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77beb5d3e17448e1887e71acc87ff552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset created, with:\n",
      "\t1511 sentences\n",
      "\t20319 word tokens\n",
      "\t13.447385837193911 avg. sentence length\n",
      "\n",
      "\n",
      "SentenceVAE(\n",
      "  (embedding): Embedding(10009, 300)\n",
      "  (embedding_dropout): Dropout(p=0.5)\n",
      "  (encoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (decoder_rnn): GRU(300, 256, batch_first=True)\n",
      "  (hidden2mean): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (hidden2logv): Linear(in_features=256, out_features=16, bias=True)\n",
      "  (latent2hidden): Linear(in_features=16, out_features=256, bias=True)\n",
      "  (outputs2vocab): Linear(in_features=256, out_features=10009, bias=True)\n",
      ")\n",
      "SPLIT = train\n",
      "TRAIN Batch 0000/267, Loss  122.4337, NLL-Loss  122.4329, KL-Loss    0.4094, KL-Weight  0.002\n",
      "TRAIN Batch 0050/267, Loss   81.0064, NLL-Loss   80.9780, KL-Loss   13.0064, KL-Weight  0.002\n",
      "TRAIN Batch 0100/267, Loss   86.9717, NLL-Loss   86.8705, KL-Loss   40.9368, KL-Weight  0.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-16:\n",
      "Process Process-13:\n",
      "Process Process-18:\n",
      "Process Process-14:\n",
      "Process Process-15:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "Process Process-17:\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/root/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/root/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/root/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "  File \"/root/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 104, in get\n",
      "    if not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/root/anaconda3/lib/python3.6/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "Exception ignored in: <bound method _DataLoaderIter.__del__ of <torch.utils.data.dataloader._DataLoaderIter object at 0x7fadccec5e10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/root/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 397, in __del__\n",
      "    def __del__(self):\n",
      "  File \"/root/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 1074) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-5ac95ca0ab5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-57-ad259652b876>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# train the model and record its performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrackers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# write args to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-19e0970d723c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, datasets, args)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mlogp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'length'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m# loss calculation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/research/dl-research/lv-nlm/models/bowman.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_sequence, length)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;31m# project outputs to vocab\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs2vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datasets = run_experiment(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing/Generating Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate samples and interpolations\n",
    "# test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
